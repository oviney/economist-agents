name: Nightly Agent Evaluation

on:
  schedule:
    # Run daily at 00:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch:
    # Allow manual trigger via GitHub UI

jobs:
  agent-eval:
    name: SM Effectiveness Benchmark
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run SM Effectiveness Benchmark
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python scripts/benchmarks/measure_sm_effectiveness.py
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sm-effectiveness-report-${{ github.run_number }}
          path: docs/metrics/sm_effectiveness_report.json
          retention-days: 30
